{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI Generation with Keras\n",
    "\n",
    "The code below creates an LSTM RNN, and creates a model using various midi files as training data. The model generated is then used to produce some tunes... hopefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import music21 as m21\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = Path('/home/tony/repos/rnn_midi_generator')\n",
    "\n",
    "checkpoints_folder = project_folder / 'checkpoints'\n",
    "data_folder = project_folder / 'data'\n",
    "output_folder = project_folder / 'output'\n",
    "\n",
    "midi_folder = Path('/c/Users/Josh/Downloads/50000 MIDI FILES/Classical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather training data\n",
    "Scan `midi_folder` for `.mid` files and parse each one, storing the result in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of midi files parsed: 17\n"
     ]
    }
   ],
   "source": [
    "number_of_files_parsed = 0\n",
    "notes = []\n",
    "\n",
    "for file in midi_folder.glob('*.mid'):\n",
    "    midi = m21.converter.parse(file)\n",
    "\n",
    "    try:  # file has instrument parts\n",
    "        s2 = m21.instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse()\n",
    "    except:  # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, m21.note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, m21.chord.Chord):\n",
    "            # notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "            notes.extend([str(note.pitch) for note in element._notes])\n",
    "    number_of_files_parsed += 1\n",
    "\n",
    "print(f'Number of midi files parsed: {number_of_files_parsed}')\n",
    "\n",
    "with open(data_folder / 'notes', 'wb') as filepath:\n",
    "    pickle.dump(notes, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create note:int mapping\n",
    "Create a dictionary mapping each note to an integer representing its position in an ordered list of all the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'A6': 5, 'B-1': 6, 'B-2': 7, 'B-3': 8, 'B-4': 9, 'B-5': 10, 'B1': 11, 'B2': 12, 'B3': 13, 'B4': 14, 'B5': 15, 'B6': 16, 'C#2': 17, 'C#3': 18, 'C#4': 19, 'C#5': 20, 'C#6': 21, 'C1': 22, 'C2': 23, 'C3': 24, 'C4': 25, 'C5': 26, 'C6': 27, 'D1': 28, 'D2': 29, 'D3': 30, 'D4': 31, 'D5': 32, 'D6': 33, 'E-1': 34, 'E-2': 35, 'E-3': 36, 'E-4': 37, 'E-5': 38, 'E-6': 39, 'E1': 40, 'E2': 41, 'E3': 42, 'E4': 43, 'E5': 44, 'E6': 45, 'F#1': 46, 'F#2': 47, 'F#3': 48, 'F#4': 49, 'F#5': 50, 'F#6': 51, 'F1': 52, 'F2': 53, 'F3': 54, 'F4': 55, 'F5': 56, 'F6': 57, 'G#1': 58, 'G#2': 59, 'G#3': 60, 'G#4': 61, 'G#5': 62, 'G#6': 63, 'G1': 64, 'G2': 65, 'G3': 66, 'G4': 67, 'G5': 68, 'G6': 69}\n"
     ]
    }
   ],
   "source": [
    "pitchnames = sorted(set(notes))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "print(note_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input sequences and corresponding outputs\n",
    "The notes are mapped to their integer representation for the neural network to be able to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes: 39846\n"
     ]
    }
   ],
   "source": [
    "network_input = []\n",
    "network_output = []\n",
    "sequence_length = 30\n",
    "notes_length = len(notes)\n",
    "notes_as_ints = list(map(lambda x: note_to_int[x], notes))\n",
    "\n",
    "print(f'Number of notes: {notes_length}')\n",
    "\n",
    "for i in range(notes_length - sequence_length):\n",
    "    sequence_in = notes_as_ints[i:i + sequence_length]\n",
    "    sequence_out = notes_as_ints[i + sequence_length]\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform input and output\n",
    "Reshape the `network_input` into a format compatible with LSTM layers and normalize. One-hot encode the `network_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique notes: 70\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda3/envs/music_gen/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pitchnames_length = len(pitchnames)\n",
    "print(f'Number of unique notes: {pitchnames_length}')\n",
    "normalized_network_input = np.reshape(\n",
    "    network_input, \n",
    "    (len(network_input), sequence_length, 1),\n",
    ")\n",
    "normalized_network_input = normalized_network_input / float(pitchnames_length)\n",
    "network_output = to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Make a sequential model with several LSTM layers, 2 dense layers, ...\n",
    "\n",
    "LSTM is used as the data is time-dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 30, 512)           1052672   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                17990     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 70)                0         \n",
      "=================================================================\n",
      "Total params: 5,400,390\n",
      "Trainable params: 5,400,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512,\n",
    "               input_shape=(normalized_network_input.shape[1],\n",
    "                            normalized_network_input.shape[2]),\n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(pitchnames_length))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "This might take a while..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath= checkpoints_folder / 'model_{epoch:02d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath.absolute,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 1088/39816 [..............................] - ETA: 35:03 - loss: 4.5673"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    normalized_network_input,\n",
    "    network_output,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    callbacks=callbacks_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose random start pattern from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = randint(0, len(network_input) - 1)\n",
    "pattern = network_input[start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create int:note mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_note = dict((v, k) for k, v in note_to_int.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict 500 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = []\n",
    "\n",
    "for i in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(pitchnames_length)\n",
    "    \n",
    "    predicted_note = model.predict(prediction_input)\n",
    "    index = np.argmax(predicted_note)\n",
    "    note = int_to_note[index]\n",
    "    prediction_output.append(note)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MIDI file from predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset= 0\n",
    "output_notes = []\n",
    "\n",
    "for note, velocity in prediction_output:\n",
    "    print(note)\n",
    "    new_note = m21.note.Note(note)\n",
    "    new_note.offset = offset\n",
    "    new_note.storedInstrument = m21.instrument.Piano()\n",
    "    output_notes.append(new_note)\n",
    "\n",
    "    offset += 0.5  # increase offset each iteration so that notes do not stack\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "midi_stream = m21.stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp=output_folder / f'{timestamp}.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_gen",
   "language": "python",
   "name": "music_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "468px",
    "left": "1024px",
    "top": "172px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
