{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI Generation with Keras\n",
    "\n",
    "The code below creates an LSTM RNN, and creates a model using various midi files as training data. The model generated is then used to produce some tunes... hopefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import music21 as m21\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = Path('/home/tony/repos/rnn_midi_generator')\n",
    "\n",
    "checkpoints_folder = project_folder / 'checkpoints'\n",
    "data_folder = project_folder / 'data'\n",
    "output_folder = project_folder / 'output'\n",
    "\n",
    "midi_folder = Path('/c/Users/Josh/Downloads/50000 MIDI FILES/Classical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather training data\n",
    "Scan `midi_folder` for `.mid` files and parse each one, storing the result in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_files_parsed = 0\n",
    "notes = []\n",
    "\n",
    "for file in midi_folder.glob('*.mid'):\n",
    "    midi = m21.converter.parse(file)\n",
    "\n",
    "    try:  # file has instrument parts\n",
    "        s2 = m21.instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[0].recurse()\n",
    "    except:  # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, m21.note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, m21.chord.Chord):\n",
    "            # notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "            notes.extend([str(note.pitch) for note in element._notes])\n",
    "    number_of_files_parsed += 1\n",
    "\n",
    "print(f'Number of midi files parsed: {number_of_files_parsed}')\n",
    "\n",
    "with open(data_folder / 'notes', 'wb') as filepath:\n",
    "    pickle.dump(notes, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create note:int mapping\n",
    "Create a dictionary mapping each note to an integer representing its position in an ordered list of all the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchnames = sorted(set(notes))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "print(note_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input sequences and corresponding outputs\n",
    "The notes are mapped to their integer representation for the neural network to be able to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input = []\n",
    "network_output = []\n",
    "sequence_length = 30\n",
    "notes_length = len(notes)\n",
    "notes_as_ints = list(map(lambda x: note_to_int[x], notes))\n",
    "\n",
    "print(f'Number of notes: {notes_length}')\n",
    "\n",
    "for i in range(notes_length - sequence_length):\n",
    "    sequence_in = notes_as_ints[i:i + sequence_length]\n",
    "    sequence_out = notes_as_ints[i + sequence_length]\n",
    "    network_input.append(sequence_in)\n",
    "    network_output.append(sequence_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform input and output\n",
    "Reshape the `network_input` into a format compatible with LSTM layers and normalize. One-hot encode the `network_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchnames_length = len(pitchnames)\n",
    "print(f'Number of unique notes: {pitchnames_length}')\n",
    "normalized_network_input = np.reshape(\n",
    "    network_input, \n",
    "    (len(network_input), sequence_length, 1),\n",
    ")\n",
    "normalized_network_input = normalized_network_input / float(pitchnames_length)\n",
    "network_output = to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "Make a sequential model with several LSTM layers, 2 dense layers, ...\n",
    "\n",
    "LSTM is used as the data is time-dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512,\n",
    "               input_shape=(normalized_network_input.shape[1],\n",
    "                            normalized_network_input.shape[2]),\n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(pitchnames_length))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "This might take a while..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath= checkpoints_folder / 'model_{epoch:02d}.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath.absolute,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    normalized_network_input,\n",
    "    network_output,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    callbacks=callbacks_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose random start pattern from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = randint(0, len(network_input) - 1)\n",
    "pattern = network_input[start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create int:note mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_note = dict((v, k) for k, v in note_to_int.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict 500 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = []\n",
    "\n",
    "for i in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(pitchnames_length)\n",
    "    \n",
    "    predicted_note = model.predict(prediction_input)\n",
    "    index = np.argmax(predicted_note)\n",
    "    note = int_to_note[index]\n",
    "    prediction_output.append(note)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MIDI file from predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "for note, velocity in prediction_output:\n",
    "    new_note = m21.note.Note(note)\n",
    "    new_note.offset = offset\n",
    "    new_note.storedInstrument = m21.instrument.Piano()\n",
    "    output_notes.append(new_note)\n",
    "    offset += 0.5  # increase offset each iteration so that notes do not stack\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "midi_stream = m21.stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp=output_folder / f'{timestamp}.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_gen",
   "language": "python",
   "name": "music_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "468px",
    "left": "1024px",
    "top": "172px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
